{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Setting up Google Colab and importing libraries**"
      ],
      "metadata": {
        "id": "j85a4v72tjIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This step involves setting up the environment in Google Colab and importing necessary libraries like numpy for numerical operations, sklearn for text processing (CountVectorizer, TF-IDFVectorizer), gensim for Word Embeddings (Word2Vec), and spacy for Named Entity Recognition (NER)."
      ],
      "metadata": {
        "id": "2pRsKJxGuAxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from gensim.models import Word2Vec\n",
        "import spacy"
      ],
      "metadata": {
        "id": "a_bFviXjsGLb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Define the documents**"
      ],
      "metadata": {
        "id": "HiH9ggv4tnYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Here, we've defined a list of text documents that represent different actions or queries related to wedding items like gown, flowers, and diamond ring. These documents will be used for text processing and analysis."
      ],
      "metadata": {
        "id": "MrLNmlvBuL0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"User selected Wedding gown.\",\n",
        "    \"User ordered on-line rose flowers.\",\n",
        "    \"User searched diamond ring.\",\n",
        "    \"User selected white wedding gown, online flowers, 3 carat diamond ring.\"\n",
        "]"
      ],
      "metadata": {
        "id": "WeCPsfOPsI9h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Text Preprocessing**"
      ],
      "metadata": {
        "id": "B7oihBcRtumq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The preprocess_text function converts the text to lowercase and tokenizes it, splitting it into individual words. We've applied this function to each document in the list, resulting in a cleaned and tokenized representation of the text.\n",
        "\n",
        "### Additionally, we've used SpaCy's Named Entity Recognition (NER) to extract entities like names, organizations, or locations present in the documents."
      ],
      "metadata": {
        "id": "-s8FXPMsuQw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert text to lowercase\n",
        "    return text.split()  # Tokenize text\n",
        "\n",
        "cleaned_documents = [preprocess_text(doc) for doc in documents]\n",
        "print(\"Cleaned and Tokenized Documents:\", cleaned_documents)\n",
        "\n",
        "# Named Entity Recognition\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "for doc in documents:\n",
        "    entities = nlp(doc)\n",
        "    for ent in entities.ents:\n",
        "        print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ7NDIPOsMHk",
        "outputId": "61961917-8574-4339-fe48-6409f7a65bac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned and Tokenized Documents: [['user', 'selected', 'wedding', 'gown.'], ['user', 'ordered', 'on-line', 'rose', 'flowers.'], ['user', 'searched', 'diamond', 'ring.'], ['user', 'selected', 'white', 'wedding', 'gown,', 'online', 'flowers,', '3', 'carat', 'diamond', 'ring.']]\n",
            "3 CARDINAL\n",
            "carat ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Vectorization Techniques**"
      ],
      "metadata": {
        "id": "AjrWTKusucsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CountVectorizer and TF-IDF Vectorizer\n",
        "### We've used both CountVectorizer and TF-IDFVectorizer from sklearn to convert the text data into numerical representations.\n",
        "\n",
        "### **CountVectorizer:** Converts text into a matrix of token counts, representing the frequency of each word in the document.\n",
        "### **TF-IDFVectorizer:** Transforms text into a TF-IDF (Term Frequency-Inverse Document Frequency) matrix, which gives a weight to each term based on its frequency in the document and across the entire corpus."
      ],
      "metadata": {
        "id": "8m1EMCSwuhQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X_count = vectorizer.fit_transform(documents)\n",
        "\n",
        "# TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Count Vectorizer Matrix:\")\n",
        "print(X_count.toarray())\n",
        "print(\"TF-IDF Vectorizer Matrix:\")\n",
        "print(X_tfidf.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0t1N16isQYC",
        "outputId": "53acdfd6-6c05-4050-a98d-9f5cee333948"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count Vectorizer Matrix:\n",
            "[[0 0 0 1 0 0 0 0 0 0 0 1 1 1 0]\n",
            " [0 0 1 0 1 1 0 1 0 1 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0 0 1 0 1 0 1 0 0]\n",
            " [1 1 1 1 0 0 1 0 1 0 0 1 1 1 1]]\n",
            "TF-IDF Vectorizer Matrix:\n",
            "[[0.         0.         0.         0.53931298 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.53931298\n",
            "  0.35696573 0.53931298 0.        ]\n",
            " [0.         0.         0.3563895  0.         0.45203489 0.45203489\n",
            "  0.         0.45203489 0.         0.45203489 0.         0.\n",
            "  0.23589056 0.         0.        ]\n",
            " [0.         0.4970962  0.         0.         0.         0.\n",
            "  0.         0.         0.4970962  0.         0.6305035  0.\n",
            "  0.32902288 0.         0.        ]\n",
            " [0.37791387 0.29795164 0.29795164 0.29795164 0.         0.\n",
            "  0.37791387 0.         0.29795164 0.         0.         0.29795164\n",
            "  0.19721114 0.29795164 0.37791387]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word Embeddings using Word2Vec**\n",
        "### We've employed Word2Vec from the gensim library to create word embeddings, which capture semantic relationships between words in a continuous vector space. However, if certain words like 'gown' are not present in the vocabulary, it might be due to the training parameters or the word's frequency in the provided text."
      ],
      "metadata": {
        "id": "2HolnyoRu0Yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated Word2Vec model training\n",
        "word2vec_model = Word2Vec(sentences=cleaned_documents, vector_size=100, window=5, min_count=1, workers=4)\n",
        "word_vectors = word2vec_model.wv\n",
        "\n",
        "# Checking for available words in the Word2Vec model\n",
        "available_words = word_vectors.index_to_key\n",
        "print(\"Available Words in the Word2Vec Model:\", available_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3VGq6aFsT16",
        "outputId": "bbde6551-3aa6-4f54-c980-84623c9ab13e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available Words in the Word2Vec Model: ['user', 'selected', 'wedding', 'ring.', 'diamond', 'rose', 'gown.', 'ordered', 'on-line', 'carat', 'flowers.', '3', 'white', 'gown,', 'online', 'flowers,', 'searched']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Calculate Similarity**"
      ],
      "metadata": {
        "id": "VGsxpcMsu55P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In this step, we've calculated similarity scores between documents using two methods:\n",
        "\n",
        "### **Cosine Similarity with TF-IDF Vectors:** Using cosine_similarity from sklearn, we computed the similarity between documents based on their TF-IDF representations.\n",
        "### **Word Embeddings Similarity:** We attempted to calculate the similarity between words 'wedding' and 'gown' using the Word2Vec model. If the word 'gown' is not available in the Word2Vec model's vocabulary, it won't be possible to compute the similarity."
      ],
      "metadata": {
        "id": "DSQiSW_wu_rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine similarity between TF-IDF vectors\n",
        "cos_sim_tfidf = cosine_similarity(X_tfidf, X_tfidf)\n",
        "print(\"Cosine Similarity Matrix - TF-IDF:\")\n",
        "print(cos_sim_tfidf)\n",
        "\n",
        "# Cosine similarity using Word Embeddings (Word2Vec)\n",
        "# Example: Calculate similarity between 'Wedding' and 'Gown'\n",
        "similarity = word_vectors.similarity('wedding', 'gown.')\n",
        "print(\"Similarity between 'Wedding' and 'Gown':\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og5WYUJtsVVC",
        "outputId": "bc340953-d0ea-4444-f0cb-8c8c8988c165"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity Matrix - TF-IDF:\n",
            "[[1.         0.08420485 0.1174499  0.55246518]\n",
            " [0.08420485 1.         0.07761339 0.15270708]\n",
            " [0.1174499  0.07761339 1.         0.36110824]\n",
            " [0.55246518 0.15270708 0.36110824 1.        ]]\n",
            "Similarity between 'Wedding' and 'Gown': 0.14595059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion:**"
      ],
      "metadata": {
        "id": "XcHjJKJ7vOjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Vector Space Model involves turning text into numbers for analysis. We clean and tokenize the text, then convert it using methods like CountVectorizer or TF-IDFVectorizer. Word Embeddings capture word meanings. Calculating similarity helps compare documents. Adjustments improve accuracy, and this model can aid in various text analyses like sentiment or topic identification."
      ],
      "metadata": {
        "id": "ZoMG2OGqvTL_"
      }
    }
  ]
}